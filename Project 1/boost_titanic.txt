Number of Estimators Mean Train Score [0.82968946 0.88934464 0.9219052  0.99840573 1.         1.        ] 

Number of Estimators Mean Test Score [0.61476131 0.49535907 0.44807804 0.4954587  0.49909921 0.49728518] 

Learning Rate Mean Train Score [0.80464884 0.80464884 0.80464884 0.81785239 0.8426717  0.89822355
 0.9731342  1.         0.35385728 0.42079294] 

Learning Rate Mean Test Score [0.58463678 0.58463678 0.58463678 0.59560399 0.60830635 0.46080946
 0.46813616 0.51092154 0.34323371 0.32516812] 

 from base import *

import numpy as np
import pandas as pd
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.model_selection import validation_curve
from sklearn.model_selection import learning_curve
from sklearn.metrics import accuracy_score

from sklearn.datasets import load_breast_cancer
import _pickle as cPickle
from sklearn.preprocessing import StandardScaler
from sklearn.utils import resample
import time

import matplotlib
matplotlib.use("TkAgg")
from matplotlib import pyplot as plt


def train_boost(model_name):
    
    # Post - pruning alpha
    classifier = GradientBoostingClassifier(random_state= 10)
    
    parameters = {
        "n_estimators":  [10, 50, 100, 500, 1000, 5000],
        "learning_rate": np.logspace(-4,1,10),
    }

    train_sizes =  np.linspace(0.1,1.0,10)
    
    train_score, test_score = cv_validation(classifier, "n_estimators", parameters["n_estimators"], x_train, y_train)
    plot_train_val_curve(train_score, test_score, parameters["n_estimators"], "Number of Estimators","n_estimators", dataset)

    train_score, test_score = cv_validation(classifier, "learning_rate", parameters["learning_rate"], x_train, y_train)
    plot_train_val_curve(train_score, test_score, parameters["learning_rate"], "Learning Rate", "learning_rate", dataset)

    grid = GridSearchCV(classifier,
                        param_grid = parameters,
                        cv = 5,
                        verbose = True)
    grid.fit(x_train, y_train)
    
    final_model = grid.best_estimator_
    save_model(final_model, model_name)
    print("best parameters", grid.best_params_)
    
    best_classifier = GradientBoostingClassifier(random_state= 10,
                                             n_estimators = grid.best_params_["n_estimators"],
                                             learning_rate = grid.best_params_["learning_rate"])
    train_score, test_score, _ = learning(best_classifier, train_sizes, x_train, y_train)
    plot_train_val_curve(train_score, test_score, train_sizes, "Ratio of Train Sizes", "train_size", dataset)

    get_train_time(best_classifier, x_train, y_train)
    if True:
        start_time = time.time()
        test(model_name, x_train, y_train, x_test, y_test, classes, dataset, "boost")
        end_time = time.time()
        time_to_test = end_time - start_time
        print("time to test", time_to_test)
    
if __name__ == "__main__":
    x_train, y_train, x_test, y_test = load_dataset_2()
    
    '''x_train = x_train.head(10)
    y_train = y_train.head(10)
    x_test = x_test.head(10)
    y_test = y_test.head(10)'''
    
    dataset = "titanic_"
    classes = ["Not Survived","Survived"]
    print(x_train.describe())
    print(y_train.info())
    print(y_train.value_counts())
    print("\n \n")
    
    train_boost("./models/boost_titanic.pkl")
    